{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "import pickle\n",
    "\n",
    "from openai import OpenAI\n",
    "api_key=json.load(open(\"api.json\"))[0]\n",
    "client = OpenAI(api_key=api_key, base_url=\"https://api.deepseek.com\")\n",
    "\n",
    "import ollama\n",
    "model=\"llama3.1:8b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d13d3d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction='''You are an expert NLU data generation assistant for a campus chatbot.\n",
    "Your task is to generate {num_query} varied data items for given entity and intent.\n",
    "**Instructions:**\n",
    "1. You should generate {num_query} possible queries corresponding to the given entity and intent.\n",
    "2. The output should be a vaild json snippet like {example}\n",
    "3. The {num_query} queries should be included in a list.\n",
    "in json file that is \"query\":[{num_query} generated] \n",
    "4. Each possible query must contain one or some of the given entities.\n",
    "5. Each possible query must contain one or some of the given intents.\n",
    "6. You cannot add new eneities in the generated query! \n",
    "For example:\n",
    "\"entity\":{\"gym\":\"facility_name\"}, \"generated_query\":\"When does the gym open on weekends\"\n",
    "then a NEW entity \"weekend\":\"time\" is added.\n",
    "7. Output json snippet ONLY. \n",
    "\n",
    "**Exapmle:**\n",
    "{\n",
    "  \"query\": [\"where is Nasi Kandar restaurant?\", \"how can i go to Nasi Kandar restaurant?\"],\n",
    "  \"intent\": \"find_location\",\n",
    "  \"entities\": [\n",
    "    {\"Nasi Kandar restaurant\":\"reataurant_name\"} \n",
    "  ]\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "683d75ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLU_data_generator:\n",
    "    def __init__(self,intent_lib_path=r\"data\\IE\\intent_lib.json\"):\n",
    "        self.data=json.load(open(intent_lib_path,\"r\",encoding=\"utf-8\"))\n",
    "        self.categories=list(self.data.keys())\n",
    "        self.responses={\n",
    "          category:None for category in self.categories\n",
    "        }\n",
    "    \n",
    "    def create_prompt(self,category,num_query):\n",
    "        message_set=[\n",
    "          {\"role\":\"system\",\"content\":instruction}\n",
    "          ]\n",
    "        for intent in self.data[category][1:]:\n",
    "          for entity_name in self.data[category][0]:\n",
    "            prompt=f\"\"\"**Your Task:**\n",
    "            Generate {num_query} new and unique query examples for the intent '{intent}' containing entity {entity_name}:{category}.\n",
    "            \"\"\"\n",
    "            message_set.append({\n",
    "              \"role\":\"user\",\n",
    "              \"content\":prompt\n",
    "            })\n",
    "        return message_set\n",
    "    \n",
    "    def get_response(self,category,num_query):\n",
    "      message_set=self.create_prompt(category,num_query)\n",
    "      response_set=[]\n",
    "      for msg in tqdm(message_set[1:],desc=f\"Generating data for {category}\"):\n",
    "        # response=client.chat.completions.create(\n",
    "        #     model=\"deepseek-chat\",\n",
    "        #     messages=[\n",
    "        #       message_set[0],msg\n",
    "        #     ],\n",
    "        #     stream=False\n",
    "        # ).choices[0].message.content\n",
    "        response=ollama.chat(model=model, messages=[\n",
    "              message_set[0],msg\n",
    "            ])[\"message\"][\"content\"]\n",
    "\n",
    "        response=re.sub(\n",
    "          pattern=r\"```json\\n|\\n```\",\n",
    "          repl='',\n",
    "          string=response\n",
    "        )\n",
    "        response_set.append(response)\n",
    "      self.responses[category]=response_set\n",
    "\n",
    "    def save_data(self,file_path):\n",
    "        with open(file_path,\"a\",encoding=\"utf-8\") as f:\n",
    "            f.write(\"{\\n\")\n",
    "            for category in self.categories:\n",
    "                f.write(f'\"{category}\":[\\n')\n",
    "                for data_item in self.responses[category]:\n",
    "                    f.write(data_item)\n",
    "                    f.write(\",\\n\")\n",
    "                f.write(\"],\\n\")\n",
    "            f.write(\"}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9eab320a",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator=NLU_data_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fff5cb55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b079733ceed041b1bad09ce677afed77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating data:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f670eb6f6e904ead840e6c192aaec05c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating data for business:   0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e196a7a237b4683b8c0ab02b43cc8e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating data for restaurant:   0%|          | 0/272 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0665625e27a34a34b56f62f63ac27c71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating data for facility:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c3a1a7907904434a9bb7a804653a31c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating data for building:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52f689b67e6447fbb3244a00896d1a9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating data for handbook:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'py_code/data/generator.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m tqdm(generator\u001b[38;5;241m.\u001b[39mcategories,desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerating data\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m      2\u001b[0m     generator\u001b[38;5;241m.\u001b[39mget_response(c,\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpy_code/data/generator.pkl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      4\u001b[0m     pickle\u001b[38;5;241m.\u001b[39mdump(generator, f)\n",
      "File \u001b[1;32mc:\\Users\\DominicMin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'py_code/data/generator.pkl'"
     ]
    }
   ],
   "source": [
    "for c in tqdm(generator.categories,desc=\"Generating data\"):\n",
    "    generator.get_response(c,5)\n",
    "with open(\"py_code/data/generator.pkl\", \"wb\") as f:\n",
    "    pickle.dump(generator, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f33d9d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/generator.pkl\", \"wb\") as f:\n",
    "    pickle.dump(generator, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6dfafdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"data/generator.pkl\",\"rb\") as f:\n",
    "    generator=pickle.load(f)\n",
    "\n",
    "generator.save_data(\"data/generator.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
