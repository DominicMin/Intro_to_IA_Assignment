{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "from openai import OpenAI\n",
    "api_key=json.load(open(\"api.json\"))[0]\n",
    "client = OpenAI(api_key=api_key, base_url=\"https://api.deepseek.com\")\n",
    "\n",
    "import ollama\n",
    "model=\"llama3.1:8b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d13d3d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "intent_instruction='''You are an expert NLU data generation assistant for a campus chatbot.\n",
    "Your task is to generate {num_query} varied data items for given entity and intent.\n",
    "**Instructions:**\n",
    "1. You should generate {num_query} possible queries corresponding to the given entity and intent.\n",
    "2. The output should be a vaild json snippet like {example}\n",
    "3. The {num_query} queries should be included in a list.\n",
    "in json file that is \"query\":[{num_query} generated] \n",
    "4. Each possible query must contain one or some of the given entities.\n",
    "5. Each possible query must contain one or some of the given intents.\n",
    "6. You CANNOT add new eneities in the generated query! \n",
    "For example:\n",
    "\"intent\": \"ask_business_location\", \"generated_query\":\"What are the business hours of KIMS SALON?\"\n",
    "then a NEW intent \"ask_business_time\" is added.\n",
    "7. Output json snippet ONLY. \n",
    "\n",
    "**Exapmle:**\n",
    "{\n",
    "  \"query\": [\"where is Nasi Kandar restaurant?\", \"how can i go to Nasi Kandar restaurant?\"],\n",
    "  \"intent\": \"ask_restaurant_location\",\n",
    "  \"entities\": [\n",
    "    {\"Nasi Kandar restaurant\":\"restaurant_name\"} \n",
    "  ]\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "683d75ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLU_data_generator:\n",
    "    def __init__(self,intent_lib_path=r\"data\\IE\\intent_lib.json\"):\n",
    "        self.data=json.load(open(intent_lib_path,\"r\",encoding=\"utf-8\"))\n",
    "        self.categories=list(self.data.keys())\n",
    "        self.responses={\n",
    "          category:None for category in self.categories\n",
    "        }\n",
    "    \n",
    "    def create_prompt(self,category,num_query):\n",
    "        message_set=[\n",
    "          {\"role\":\"system\",\"content\":intent_instruction}\n",
    "          ]\n",
    "        for intent in self.data[category][1:]:\n",
    "          for entity_name in self.data[category][0]:\n",
    "            prompt=f\"\"\"**Your Task:**\n",
    "            Generate {num_query} new and unique query examples for the intent '{intent}' containing entity {entity_name}:{category}.\n",
    "            \"\"\"\n",
    "            message_set.append({\n",
    "              \"role\":\"user\",\n",
    "              \"content\":prompt\n",
    "            })\n",
    "        return message_set\n",
    "    \n",
    "    def get_response(self,category,num_query):\n",
    "      message_set=self.create_prompt(category,num_query)\n",
    "      response_set=[]\n",
    "      for msg in tqdm(message_set[1:],desc=f\"Generating data for {category}\"):\n",
    "        try:\n",
    "            # response=client.chat.completions.create(\n",
    "            #     model=\"deepseek-chat\",\n",
    "            #     messages=[\n",
    "            #       message_set[0],msg\n",
    "            #     ],\n",
    "            #     stream=False\n",
    "            # ).choices[0].message.content\n",
    "            response=ollama.chat(model=model, messages=[\n",
    "                  message_set[0],msg\n",
    "                ])[\"message\"][\"content\"]\n",
    "\n",
    "            response=re.sub(\n",
    "              pattern=r\"```json\\n|\\n```\",\n",
    "              repl='',\n",
    "              string=response\n",
    "            )\n",
    "            try:\n",
    "                json.loads(response)\n",
    "                response_set.append(response)\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Warning: Invalid JSON response for {category}, skipping this item\")\n",
    "                continue\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error generating response for {category}: {e}\")\n",
    "            continue\n",
    "            \n",
    "      self.responses[category]=response_set\n",
    "\n",
    "    def save_data(self,file_path):\n",
    "        # 使用写入模式而不是追加模式\n",
    "        with open(file_path,\"w\",encoding=\"utf-8\") as f:\n",
    "            f.write(\"{\\n\")\n",
    "            valid_categories = []\n",
    "            \n",
    "            # 先过滤出有有效数据的类别\n",
    "            for category in self.categories:\n",
    "                if (self.responses[category] is not None and \n",
    "                    len(self.responses[category]) > 0):\n",
    "                    valid_categories.append(category)\n",
    "            \n",
    "            for i, category in enumerate(valid_categories):\n",
    "                f.write(f'\"{category}\":[\\n')\n",
    "                \n",
    "                # 过滤出有效的JSON数据项\n",
    "                valid_items = []\n",
    "                for data_item in self.responses[category]:\n",
    "                    try:\n",
    "                        # 验证JSON格式\n",
    "                        json.loads(data_item)\n",
    "                        valid_items.append(data_item)\n",
    "                    except json.JSONDecodeError:\n",
    "                        print(f\"Warning: Skipping invalid JSON item in {category}\")\n",
    "                        continue\n",
    "                \n",
    "                # 写入有效的数据项\n",
    "                for j, data_item in enumerate(valid_items):\n",
    "                    f.write(data_item)\n",
    "                    if j == len(valid_items) - 1:\n",
    "                        f.write(\"\\n\")\n",
    "                    else:\n",
    "                        f.write(\",\\n\")\n",
    "                \n",
    "                # 添加类别间的逗号\n",
    "                if i == len(valid_categories) - 1:\n",
    "                    f.write(\"]\\n\")\n",
    "                else:\n",
    "                    f.write(\"],\\n\")\n",
    "                    \n",
    "            f.write(\"}\")\n",
    "            \n",
    "        print(f\"数据已保存到 {file_path}\")\n",
    "        print(f\"成功保存的类别: {valid_categories}\")\n",
    "        for category in self.categories:\n",
    "            if category not in valid_categories:\n",
    "                print(f\"警告: {category} 类别没有有效数据\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9eab320a",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator=NLU_data_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fff5cb55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7043c251c2b541c28126e99c44172e9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating data:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bb33aeae8234529b7f86abfe858bfb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating data for business:   0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8baabd11fde74135b3166e32ee2b00f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating data for restaurant:   0%|          | 0/272 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52b559c4613a43519aedda6d8547ebe6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating data for facility:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90c349db900c46bdae07cc6dbce75e1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating data for building:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f6fa4df043b42eb992047c4883f1421",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating data for handbook:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'py_code/data/generator.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m tqdm(generator\u001b[38;5;241m.\u001b[39mcategories,desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerating data\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m      2\u001b[0m     generator\u001b[38;5;241m.\u001b[39mget_response(c,\u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpy_code/data/generator.pkl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      4\u001b[0m     pickle\u001b[38;5;241m.\u001b[39mdump(generator, f)\n",
      "File \u001b[1;32mc:\\Users\\DominicMin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'py_code/data/generator.pkl'"
     ]
    }
   ],
   "source": [
    "for c in tqdm(generator.categories,desc=\"Generating data\"):\n",
    "    generator.get_response(c,4)\n",
    "with open(\"data/generator.pkl\", \"wb\") as f:\n",
    "    pickle.dump(generator, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6dfafdfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Skipping invalid JSON item in restaurant\n",
      "Warning: Skipping invalid JSON item in restaurant\n",
      "Warning: Skipping invalid JSON item in restaurant\n",
      "Warning: Skipping invalid JSON item in facility\n",
      "Warning: Skipping invalid JSON item in facility\n",
      "Warning: Skipping invalid JSON item in facility\n",
      "Warning: Skipping invalid JSON item in building\n",
      "数据已保存到 data/intent_train_data.json\n",
      "成功保存的类别: ['business', 'restaurant', 'facility', 'building', 'handbook']\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/generator.pkl\",\"rb\") as f:\n",
    "    generator=pickle.load(f)\n",
    "generator.save_data(\"data/intent_train_data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e5e93a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
